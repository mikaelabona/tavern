Table of Contents
**Question 1: [Maxdiff Insights Summary](https://github.com/mikaelabona/tavern/blob/main/README.md#maxdiff-insights-summary)**
**Question 2: [Housing Policy Survey](https://github.com/mikaelabona/tavern/blob/main/README.md#housing-policy-survey)**
**Question 3: [Question Bank Design]([https://github.com/mikaelabona/tavern/blob/main/README.md#housing-policy-survey](https://github.com/mikaelabona/tavern/blob/main/README.md#question-bank-design))**


# MaxDiff Insights Summary

You can find the code for this portion of this exercise [here](https://github.com/mikaelabona/tavern/blob/main/maxdiff.R).

The MaxDiff experiment reveals strong, consistent patterns in which types of political messages are most persuasive to respondents. Themes emphasizing direct family-level harms, such as cuts to healthcare, food assistance, and support for veterans, performed significantly better than broader systemic or policy-oriented messages. The highest-scoring themes—Tax Cuts for the Wealthy vs. Burdens on Working Families (avg 0.651), Healthcare and Medicaid Cuts (avg 0.567), and Food Assistance and Child Hunger (avg 0.555)—all framed policy impacts as immediate threats to the wellbeing of children, low-income families, veterans, or people with urgent healthcare needs. These messages paired emotional clarity with concrete consequences, such as losing access to medicine or having to skip meals, which appear to resonate strongly across respondents. In contrast, the lowest-performing themes centered on Environmental and Clean Energy Programs (avg 0.355) and Worker Safety and Federal Employee Benefits (avg 0.382), which tended to invoke large-scale or bureaucratic harms that feel less personally relatable.

Overall, the data suggests that messages are most persuasive when they articulate clear economic tradeoffs, especially framing Trump’s policies as providing giveaways to corporations and the wealthy while placing tangible burdens on working families. Messages using specific numbers (e.g., “$50 per week in lost food assistance,” “400,000 veterans losing healthcare”) and concrete harms consistently outperformed abstract policy arguments. Emotional framing focused on family stability, children’s wellbeing, and broken promises to veterans also heightened persuasive impact. These patterns indicate that voters respond most strongly to messages linking policy decisions to immediate household consequences, rather than to broader environmental, regulatory, or institutional concerns.

For issue areas such as housing policy, these results suggest that persuasive messaging should emphasize direct affordability gains, family stability, and clear harms avoided, rather than procedural reforms or long-term economic logic. However, the applicability of these findings is limited by the lack of housing-specific MaxDiff stimuli: respondents’ preferences reflect generalizable persuasion schemas but not their reactions to particular zoning or approval reforms. Confidence in general themes is high; confidence in housing-specific predictions is moderate due to contextual ambiguity.

**Figure 1: Ranked MaxDiff Persuasiveness Scores with 95% Confidence Intervals**

This chart shows every message in the experiment, ordered from most to least persuasive. Higher-scoring messages cluster on the left, primarily representing themes centered on family well-being, healthcare, and economic fairness. Lower scoring messages (on the right) tend to come from environmental, regulatory, and bureaucratic-structure-themed items, illustrating the performance gap across issue types.

<img width="2758" height="1044" alt="image" src="https://github.com/user-attachments/assets/e5e47566-75c9-4d17-ac20-c079f75bafa6" />

---

**Figure 2: Average MaxDiff Score by Theme**

This bar chart summarizes performance at the thematic level, clearly showing that messages about economic inequality and essential services dramatically outperform messages about environmental programs or abstract government cuts. The visualization highlights broad issue categories where persuasive gains are strongest.

<img width="2738" height="1044" alt="image" src="https://github.com/user-attachments/assets/e0d8c9cf-f174-4ccb-bfde-200b1bbe6a4d" />

---

**Figure 3: Distribution of MaxDiff Scores Within Each Theme**

This boxplot displays score variation within themes, revealing that even within weaker topics (like environmental and clean energy), a few messages perform competitively, while the strongest themes (like tax fairness and healthcare cuts) maintain both high medians and consistent performance. This distributional view reinforces that message framing, not just issue category, drives persuasive strength.

<img width="2758" height="1044" alt="image" src="https://github.com/user-attachments/assets/b1f75763-6fc7-49f1-a55c-65034f0c4e69" />


# Housing Policy Survey

## Summary of Findings
The topline survey data point to a landscape where support for faster or automatic approval of compliant housing projects is **present but not consolidated**. Across the relevant questions, support generally falls in the **38–42%** range, with opposition close behind and a large share of respondents reporting that they are not sure. This combination suggests a public that recognizes the housing shortage, but is unsure about what solutions actually work.  

Respondents consistently say housing affordability is a major issue, but opinions begin to split once questions shift from broad principles to specific policies. People express interest in solutions that make it easier to build homes, but that interest drops when policies imply changes to neighborhood patterns or density. This tension–acknowledging the shortage while resisting visible change–is the main boundary condition for any campaign.

Overall, a campaign focused on streamlining approval processes is viable, especially if it centers predictability, fairness, and affordability. But success is not guaranteed. The data show that opinions are still forming, and messages that clarify the purpose and guardrails of the policy will matter.

## Data Ambiguities
Several important ambiguities limit how precisely these toplines can be interpreted:  

-	No subgroup detail. Without crosstabs, we cannot see how support varies across homeowners and renters, different types of neighborhoods, or partisan groups–all dynamics that typically shape land-use politics.
-	High uncertainty. On many key items, 20–30% of respondents say they are “not sure,” which lowers the stability of the toplines and suggests the public has limited familiarity with how housing approvals work.
-	Contradictory attitudes. Respondents strongly agree that housing costs are too high, yet hesitate when asked to support the policies required to build more homes. These inconsistencies indicate that preferences are not deeply held and may shift with new information.
-	Strong framing effects. Slight changes in language–for example, emphasizing “clear standards” versus “reducing neighborhood delays–produce large swings in support. This shows that public opinion is highly sensitive to how the issue is presented.
-	No insight into intensity of preference. The toplines report support and opposition but do not show which groups feel strongly enough to organize or vote based on this issue. In housing politics, intensity often carries more weight than raw totals.

These ambiguities mean the toplines are better understood as directional, not predictive. They highlight opportunity, but also the need for careful framing.

## Confidence in Predictions
Confidence in predictions should be moderate. The toplines offer a clear sense of where the public leans, but they are not strong enough to forecast outcomes with precision. Three factors contribute to this:

- Absence of subgroup data prevents us from identifying reliable pockets of support or opposition.  
- High uncertainty rates make attitudes more fluid and less predictable.  
- Inconsistent views across items indicate that housing preferences are still forming and could shift with new information or political cues.  
- These constraints don’t make the campaign unlikely to succeed. Rather, they show that the outcome will hinge on how the policy is framed, who communicates it, and whether the campaign addresses the underlying fears about neighborhood change and development patterns. In a context where many people are still building their mental models of the issue, strong messaging and credible messengers can meaningfully shape support.

## Strategic Implications
A campaign that wants to build support for faster approvals will need to lean into what people already agree on:  
- the housing shortage is real,  
- existing processes feel slow and unpredictable,  
- and families are struggling to find homes they can afford.  

The most compelling messages will focus on efficiency, fairness, and strong building standards–not density or zoning language. Positioning the reforms as a way to cut unnecessary delays while still protecting safety, quality, and community input is key.  

Because many respondents do not have a clear understanding of how housing approvals work, the campaign has room to define the issue. The challenge and opportunity lie in translating a procedural change into a concrete story about affordability, access, and stability for households.  


# Question Bank Design

The goal of this question bank is to create a reusable, structured, and extensible system for storing survey questions of many different types (single choice, multi-select, open-ended, MaxDiff, etc.) along with their metadata and response options. Because the dataset contains a wide range of formats—from pairwise MaxDiff items to 0–100 feeling thermometers and open-ended questions—a flat spreadsheet is not adequate for analysis or reuse. I designed a small, normalized schema represented directly in R tibbles, without requiring a database, but following relational logic so it can scale to SQL in production.

## 1. Core Structure
The question bank consists of three linked tables:

**A. questions (one row per conceptual question)**

Fields:
- question_id — stable identifier like “Q003”
- question_text — full wording
- question_type — automatically inferred (e.g., single_choice, multi_choice, maxdiff_pair, open_end, scale_0_100, ranking)
- topic — primary subject area (e.g., healthcare, elections, governance)
- field_date — first fielded date
- source_survey — originating project
- notes — optional programming notes

This table stores the essential content and metadata of each question. By separating question_type and topic from the question wording, the bank can flexibly route questions into different survey platforms, track trends, and reuse items.

**B. response_options (one row per response option per question)**

Fields:
- question_id — links back to questions
- option_value — backend-coded value
- option_label — text shown to respondents
- option_order — original order
- is_exclusive — for items like “None of the above”

Any question with selectable responses (single or multi-choice, ranking, scales) gets its options here. Questions that are open-ended simply have no rows in this table.

**C. question_tags (optional tagging table)**

Fields:
- question_id, tag

Tags allow many-to-many categorization, e.g., a question about voting security could be tagged both elections and democracy_trust. This makes searching and filtering easier than storing a single topic field.

## 2. Use of OpenAI for Metadata Classification (See code example)

Instead of manually coding 120+ questions, I used OpenAI’s API to automatically classify each question by:

1. _question_type_

Examples:
- “Select all that apply” → multi_choice
- “In your own words…” → open_end
- “Which message is more persuasive…” → maxdiff_pair
- “On a scale from 0 to 100…” → scale_0_100

2.	_topic_
Chosen from a predefined topic vocabulary (elections, healthcare, climate, economy, governance, etc.).

I passed the question_id and question_text array to the model with strict labeling instructions. The model returned a clean JSON object that mapped each ID to a question_type and topic, which I merged back into the questions table. This step reduces manual coding, scales well for future question batches, and ensures consistency across projects.

## 3. Example Output

You can find the code for this portion of the exercise [here](https://github.com/mikaelabona/tavern/blob/main/question_bank.R).
Please also see the output file to see the final categorizations/classifications [here](https://github.com/mikaelabona/tavern/blob/main/questions_final.csv). 

Questions table (excerpt):
```
# A tibble: 5 × 7
  question_id question_text                      question_type topic     field_date …
1 Q001        … universal pre-K …                single_choice education 2024-09-15 …
2 Q002        … persuasive in favor of Medicaid? maxdiff_pair  healthcare 2024-11-02 …
3 Q003        … issues most important …          multi_choice  elections  2024-10-20 …
4 Q004        … if election held today …         single_choice elections  2024-10-28 …
5 Q005        … opinion of Senator …             single_choice governance 2024-08-12 …
```

Response options (Q003 example):
```
# A tibble: 10 × 5
question_id option_label option_order
Q003        Economy …            1
Q003        Healthcare           2
Q003        Education            3
```

Tags:
```
Q001 → education  
Q002 → healthcare  
Q003 → elections  
Q004 → elections  
Q005 → governance
```

## 4. Outcome 
This question bank structure creates a flexible, scalable foundation for storing survey questions across projects. By separating question text, metadata, and response options into clean relational tables, it supports consistent reuse, easy editing, and exporting to different survey platforms. Integrating OpenAI to automatically classify each question’s type and topic dramatically reduces manual coding effort while maintaining systematic organization. The result is a compact but powerful schema that works well within an in-memory R workflow today and can be expanded into a full SQL-backed question library as survey operations grow.

